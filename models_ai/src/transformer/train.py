"""
ë¡œë˜ Transformer ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python train.py --lottery korea_645
    python train.py --lottery canada_649 --history_length 20 --epochs 100
"""

import json
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
import numpy as np
from tqdm import tqdm

import sys
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
sys.path.append(str(PROJECT_ROOT))
from models_ai.src.transformer.lotto_transformer import create_model


def load_lottery_config(lottery_id: str) -> dict:
    """ë¡œë˜ ì„¤ì • ë¡œë“œ (config/lotteries.json)"""
    config_path = PROJECT_ROOT / "config" / "lotteries.json"
    with open(config_path, "r", encoding="utf-8") as f:
        configs = json.load(f)
    if lottery_id not in configs:
        raise ValueError(f"Unknown lottery: {lottery_id}. Available: {list(configs.keys())}")
    return configs[lottery_id]


def load_training_config() -> dict:
    """í•™ìŠµ ì„¤ì • ë¡œë“œ (config/training_config.json)"""
    config_path = PROJECT_ROOT / "config" / "training_config.json"
    with open(config_path, "r", encoding="utf-8") as f:
        return json.load(f)


class LottoDataset(Dataset):
    """ë¡œë˜ ë°ì´í„°ì…‹"""
    
    def __init__(self, data_path: str, history_length: int = 10):
        with open(data_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        self.draws = [d["numbers"] for d in data["draws"]]
        self.history_length = history_length
        
        # ì‹œí€€ìŠ¤ ìƒì„±: ì´ì „ history_length íšŒì°¨ -> ë‹¤ìŒ íšŒì°¨
        self.sequences = []
        for i in range(len(self.draws) - history_length):
            input_seq = self.draws[i:i + history_length]
            target = self.draws[i + history_length]
            self.sequences.append((input_seq, target))
    
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        input_seq, target = self.sequences[idx]
        
        # ë²ˆí˜¸ -> ì¸ë±ìŠ¤ (1~N -> 0~N-1)
        input_tensor = torch.tensor(input_seq, dtype=torch.long) - 1
        target_tensor = torch.tensor(target, dtype=torch.long) - 1
        
        return input_tensor, target_tensor


def train_epoch(model, dataloader, optimizer, criterion, device, ball_count):
    """í•œ ì—í­ í•™ìŠµ"""
    model.train()
    total_loss = 0
    
    for inputs, targets in tqdm(dataloader, desc="Training", leave=False):
        inputs = inputs.to(device)
        targets = targets.to(device)
        
        optimizer.zero_grad()
        
        # Forward
        outputs = model(inputs)  # (batch, ball_count, ball_ranges)
        
        # Loss ê³„ì‚° (ê° ìœ„ì¹˜ë³„ CrossEntropy)
        loss = 0
        for i in range(ball_count):
            loss += criterion(outputs[:, i, :], targets[:, i])
        loss /= ball_count
        
        # Backward
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    return total_loss / len(dataloader)


def evaluate(model, dataloader, device, ball_count):
    """í‰ê°€: ì •í™•ë„ ê³„ì‚°"""
    model.eval()
    correct_per_position = [0] * ball_count
    total = 0
    
    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs = inputs.to(device)
            targets = targets.to(device)
            
            outputs = model(inputs)
            predictions = outputs.argmax(dim=-1)  # (batch, ball_count)
            
            for i in range(ball_count):
                correct_per_position[i] += (predictions[:, i] == targets[:, i]).sum().item()
            total += targets.size(0)
    
    accuracies = [c / total for c in correct_per_position]
    return accuracies


def train(lottery_id: str, **overrides):
    """ëª¨ë¸ í•™ìŠµ ë©”ì¸ í•¨ìˆ˜"""
    
    # ë¡œë˜ ì„¤ì • ë¡œë“œ
    lottery_config = load_lottery_config(lottery_id)
    ball_range = lottery_config["ball_range"]
    ball_ranges = ball_range[1]  # max value
    ball_count = lottery_config["ball_count"]
    data_path = PROJECT_ROOT / lottery_config["data_file"]
    
    print(f"\n{'='*50}")
    print(f"ğŸ± {lottery_config['name']} ëª¨ë¸ í•™ìŠµ")
    print(f"{'='*50}")
    print(f"ball_ranges: {ball_ranges}, ball_count: {ball_count}")
    
    # í•™ìŠµ ì„¤ì • ë¡œë“œ
    training_config = load_training_config()
    
    # CLI ì˜¤ë²„ë¼ì´ë“œ ì ìš©
    for key, value in overrides.items():
        if value is not None:
            training_config[key] = value
    
    history_length = training_config["history_length"]
    epochs = training_config["epochs"]
    batch_size = training_config["batch_size"]
    lr = training_config["learning_rate"]
    
    print(f"history_length: {history_length}, epochs: {epochs}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
    print(f"Device: {device}")
    
    # ë°ì´í„° ë¡œë“œ
    print("\në°ì´í„° ë¡œë“œ ì¤‘...")
    dataset = LottoDataset(str(data_path), history_length)
    
    # Train/Val ë¶„ë¦¬ (80/20)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    print(f"Train: {len(train_dataset)}, Val: {len(val_dataset)}")
    
    # ëª¨ë¸ ì„¤ì •
    model_config = {
        "ball_ranges": ball_ranges,
        "history_length": history_length,
        "ball_count": ball_count,
        "d_model": training_config.get("d_model", 64),
        "nhead": training_config.get("nhead", 4),
        "num_layers": training_config.get("num_layers", 2),
        "dim_feedforward": training_config.get("dim_feedforward", 128),
        "dropout": training_config.get("dropout", 0.1),
    }
    
    # ëª¨ë¸ ìƒì„±
    model = create_model(model_config).to(device)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„°: {total_params:,}")
    
    # í•™ìŠµ ì„¤ì •
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=lr)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    
    best_loss = float('inf')
    
    # ì €ì¥ ê²½ë¡œ
    save_dir = PROJECT_ROOT / "models_ai" / "trained" / "transformer"
    save_dir.mkdir(parents=True, exist_ok=True)
    model_save_path = save_dir / f"{lottery_id}.pt"
    
    # í•™ìŠµ ë£¨í”„
    print("\ní•™ìŠµ ì‹œì‘...")
    for epoch in range(epochs):
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device, ball_count)
        val_accs = evaluate(model, val_loader, device, ball_count)
        avg_acc = sum(val_accs) / ball_count
        
        scheduler.step()
        
        print(f"Epoch {epoch+1}/{epochs} | Loss: {train_loss:.4f} | Val Acc: {avg_acc:.2%}")
        
        # ìµœê³  ëª¨ë¸ ì €ì¥
        if train_loss < best_loss:
            best_loss = train_loss
            torch.save({
                "model_state_dict": model.state_dict(),
                "config": model_config,
                "lottery_id": lottery_id,
                "epoch": epoch,
                "loss": train_loss
            }, model_save_path)
            print(f"  âœ“ ëª¨ë¸ ì €ì¥: {model_save_path}")
    
    print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! ì €ì¥: {model_save_path}")


def main():
    parser = argparse.ArgumentParser(description="ë¡œë˜ Transformer ëª¨ë¸ í•™ìŠµ")
    parser.add_argument("--lottery", "-l", type=str, required=True,
                        help="ë¡œë˜ ID (ì˜ˆ: korea_645, canada_649)")
    parser.add_argument("--history_length", type=int, default=None,
                        help="ì…ë ¥ íšŒì°¨ ìˆ˜ (ê¸°ë³¸: training_config.json)")
    parser.add_argument("--epochs", type=int, default=None,
                        help="í•™ìŠµ ì—í­ ìˆ˜")
    parser.add_argument("--batch_size", type=int, default=None,
                        help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--learning_rate", type=float, default=None,
                        help="í•™ìŠµë¥ ")
    
    args = parser.parse_args()
    
    train(
        lottery_id=args.lottery,
        history_length=args.history_length,
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate
    )


if __name__ == "__main__":
    main()
